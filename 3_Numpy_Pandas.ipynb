{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 NumPy and Pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "After getting used to how Python works, it is the moment to begin getting our hands dirty with data analysis. We will study two packages: [NumPy](http://www.numpy.org/) is the fundamental **numeric computing and linear algebra** package in Python, that allows for decent data analysis. We will learn it not only for the data analysis, but more importantly because it will be a package that will be always present in our `import` section as scientists. After NumPy we will go to [Pandas](http://pandas.pydata.org/). Pandas is a dedicated data analysis package with a lot more functionalities than NumPy, making our life much easier in terms of **data visualization and manipulation**.\n",
    "\n",
    "As usual, we begin importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print('NumPy:', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Python (NumPy)\n",
    "\n",
    "NumPy is an open-source add-on module to Python that provides common mathematical and numerical routines in pre-compiled, fast functions. These are growing into highly mature packages that provide functionality that meets, or perhaps exceeds, that\n",
    "associated with common commercial software like MATLAB. The [NumPy](http://www.numpy.org/) (Numeric Python) package provides basic routines for manipulating large arrays and matrices of numeric data. The main object NumPy works with is a **homogeneous multidimensional array**. Despite its intimidating name, these are nothing but tables of numbers, each labelled by a tuple of indices.\n",
    "\n",
    "We will now explore some capabilities of NumPy that will prove very useful not only for data analyisis, but throughout all our life with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Arrays\n",
    "\n",
    "As mentioned before, the main object in NumPy is the *array*. Creating one is as easy as calling the command `array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list\n",
    "mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Create a numpy array from a list\n",
    "my1darr = np.array(mylist)\n",
    "\n",
    "# Data type of a numpy array\n",
    "print(type(my1darr))\n",
    "\n",
    "# Check content of myldarr object\n",
    "my1darr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies to multidimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array with three elemets, with three elements each.\n",
    "my2darr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "my2darr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array with three elemets, with three elements each, with a single element each\n",
    "my3darr = np.array([  [ [1], [2], [3] ], [ [4], [5], [6] ], [ [7], [8], [9] ]  ])\n",
    "my3darr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A NumPy array has a number of dimensions (or *axes*). To obtain the number of axes and the size of each of them you use the command `shape`. For 2-dimensional arrays (matrices), the order corresponds to (rows, columns)\n",
    "\n",
    "There are two different ways of calling the `shape` command, either with `np.shape(arr)` (function-like) or `arr.shape` (method-like). This is not the only command that works in both formats, and we will be finding some more in our way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape using `.shape`\n",
    "print(my1darr.shape)\n",
    "print(my2darr.shape)\n",
    "print(my3darr.shape)\n",
    "\n",
    "# Shape using `np.shape()`\n",
    "print(np.shape(my1darr))\n",
    "print(np.shape(my2darr))\n",
    "print(np.shape(my3darr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one restriction with respect to the use of lists: while you could create lists with data of different type, all the data in an array has to be of the **same type**, and it will be converted automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with floats and strings\n",
    "lst = [1., 'cat']\n",
    "print(lst[0]) # Access the first element of the list\n",
    "\n",
    "# Create a numpy array from a list with mixed data types\n",
    "arr = np.array(lst)\n",
    "print(arr[0]) # Access the first element of the array\n",
    "\n",
    "# The data type of the 1. in the list is the same data type than the 1. in the array?\n",
    "print(type(lst[0]) == type(arr[0]))\n",
    "print(type(lst[0]))\n",
    "print(type(arr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We will go deeper into indexing in a while)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with special Arrays\n",
    "\n",
    "Now we review some built-in functions that create matrices commonly used. `ones` and `zeros` return arrays of given shape and [type](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html) (default is float64), filled with ones or zeros, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zero-filled numpy array of shape 3 x 2\n",
    "np.zeros((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-filled numpy array of shape 3 x 2 x 4\n",
    "np.ones((3, 2, 4), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eye(d)` returns a 2-D, dimension-$d$ array with ones on the diagonal and zeros elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an numpy array of shape 3 x 3 with ones in the diagonal\n",
    "eye_array1 = np.eye(3)\n",
    "print(eye_array1)\n",
    "print('\\n')\n",
    "\n",
    "# Create an numpy array of shape 3 x 3 with ones in the diagonal\n",
    "eye_array2 = np.eye(5, 3)\n",
    "print(eye_array2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eye` can also create arrays with ones in upper and lower diagonals. To achieve this, you must call `eye(d, d, k)` where $k$ denotes the diagonal (positive for above the center diagonal, negative for below), or `eye(d, k=num)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an numpy array of shape 5 x 5 with ones in the diagonal shifted-up 2 positions\n",
    "print(np.eye(5, 5, 2))\n",
    "print('\\n')\n",
    "\n",
    "# Create an numpy array of shape 4 x 4 with ones in the diagonal shifted-down 1 position\n",
    "print(np.eye(4, k=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`diag`, depending on the input, either constructs a diagonal array (if the input is a 1-D array) or extracts a diagonal from a matrix (if the input is a 2-D array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a 2-D array with the array `my1darr` shifted-up 1 position with respect the diagonal \n",
    "print(my1darr)\n",
    "np.diag(my1darr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The the diagonal from the 2-D array `my2darr`\n",
    "print(my2darr)\n",
    "np.diag(my2darr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-D array with the diagonal from the 2-D array `my2darr` shifted-down 1 position with respect the diagonal \n",
    "np.diag(np.diag(my2darr), k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arange(begin, end, step)` returns evenly spaced values within a given interval. Note that the beginning point is included, but not the ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range with start at 0, stop before 16, counting up by 2\n",
    "myrange = np.arange(0, 16, 2)\n",
    "myrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Create an array of the first million of odd numbers, both with `arange` and using loops. Try timing both methods to see which one is faster. For that, use `%timeit`. This example shows how important is the use of different functions or strategies in terms of computing efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.arange(0, 2000000, 2)\n",
    "\n",
    "%timeit [i for i in range(2000000) if i % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, `linspace(begin, end, points)` returns evenly spaced numbers over a specified interval. It follows the same logic as the arange function but Here, instead of specifying the step, you specify the amount of points you want. Also with `linspace` you include the ending of the interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create line with start at 0, stop at 14, getting 7 evenly spaced points\n",
    "myline = np.linspace(0, 14, 8) \n",
    "print(myline)\n",
    "\n",
    "myline = np.linspace(0, 14, 9) \n",
    "print(myline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of `myrange` and `myline`\n",
    "print(len(myrange))\n",
    "print(len(myline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reshape` changes the shape of an array, but not its data. It basically reorganizes the content of the input array into the dimensions we provide. This is another of the commands that can be called before or after the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape `myrange` using `np.reshape()`\n",
    "print(myrange)\n",
    "print('\\n')\n",
    "\n",
    "print(np.reshape(myrange, (2, 4))) ## Reorganize in two dimensions, 2 elements in axis 0 and 4 in axis 1\n",
    "print('\\n')\n",
    "\n",
    "print(np.reshape(myrange, (4, 2))) ## Reorganize in two dimensions, 4 elements in axis 0 and 2 in axis 1\n",
    "print('\\n')\n",
    "\n",
    "# Reshape `myrange` using `.reshape()`\n",
    "print(myrange.reshape(2, 4))\n",
    "print('\\n')\n",
    "\n",
    "print(myrange.reshape(4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that, in order for these changes to be permanent, you should do a reassignment of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the reshapings above, the original array stays being the same\n",
    "myrange  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynewrange = myrange.reshape(2, 4)\n",
    "# Now that we have reassigned it is when it definitely changes shape\n",
    "mynewrange  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are trying to organize the elements in more dimensions that we can\n",
    "mynewrange = myrange.reshape(2, 4, 1, 2)\n",
    "mynewrange  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Arrays\n",
    "\n",
    "The most general command for combining arrays is `concatenate(arrs, d)`. It takes a list of arrays and concatenates them along axis $d$. Remember your 3-D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the `my3darr` 3-D numpy array\n",
    "print(my3darr)\n",
    "print('\\n')\n",
    "\n",
    "print(my3darr.shape) ## remember that shape returns the dimensions of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `my3darr` with itsef multiplied by 10 along dimension 0\n",
    "print(my3darr)\n",
    "print('-'*10)\n",
    "\n",
    "conc_along0 = np.concatenate([my3darr, 10 * my3darr])\n",
    "print(conc_along0)\n",
    "print(conc_along0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `my3darr` with itsef multiplied by 10 along dimension 1\n",
    "conc_along1 = np.concatenate([my3darr, 10 * my3darr], 1)\n",
    "print(conc_along1)\n",
    "print(conc_along1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `my3darr` with itsef multiplied by 10 along dimension 2\n",
    "conc_along2 = np.concatenate([my3darr, 10 * my3darr], 2)\n",
    "print(conc_along2)\n",
    "print(conc_along2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are trying to concatenate two arrays in dimensions that don't exist (out of bounds)\n",
    "conc_along2 = np.concatenate([my3darr, 10 * my3darr], 3)\n",
    "print(conc_along2)\n",
    "print(conc_along2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for common combinations there exist special commands. Use `vstack` to stack arrays in sequence vertically (row wise), `hstack` to stack arrays in sequence horizontally (column wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the `my1darr` 1-D numpy array from above\n",
    "print(my1darr)\n",
    "print(my1darr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack `my1darr` vertically and horizontally\n",
    "print(np.vstack([my1darr, 10 * my1darr]))\n",
    "print('\\n')\n",
    "print(np.hstack([my1darr, 10 * my1darr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the `my2darr` 2-D numpy array from above\n",
    "print(my2darr)\n",
    "print(my2darr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack `my2darr` vertically and horizontally\n",
    "print(np.vstack([my2darr, 10 * my2darr]))\n",
    "print('\\n')\n",
    "print(np.hstack([my2darr, 10 * my2darr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "You can perform easily element-wise operations on arrays of any shape. Use the typical symbols, +, -, \\*, / and \\*\\* to perform element-wise addition, subtraction, multiplication, division and power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print(x)\n",
    "print(x + 10)\n",
    "print(3 * x)\n",
    "print(1 / x)\n",
    "print(x ** (-2 / 3))\n",
    "print(2 ** x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also (and obviously) these symbols can be used to operate between two arrays, which must be of the same shape. If this is the case, they also do element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(4, 7, 1)\n",
    "print(x + y)     # [1+4, 2+5, 3+6]\n",
    "print(x * y)     # [1*4, 2*5, 3*6]\n",
    "print(x / y)     # [1/4, 2/5, 3/6]\n",
    "print(x ** y)    # [1**4, 2**5, 3**6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing vector or matrix multiplication, the command to be used is `dot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "x.dot(y)  # 1*4 + 2*5 + 3*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With python 3.5 matrix multiplication got it's own operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "x @ y  # 1*4 + 2*5 + 3*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[i + j for i in range(3, 6)] for j in range(3)])\n",
    "Y = np.diag([1, 1], 1) + np.diag([1], -2)\n",
    "\n",
    "print(X)\n",
    "print('\\n')\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operator `*` returns the elements-wise multiplication of arrays with the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X * Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operator `@` returns the product of arrays of compatible shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X @ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposing\n",
    "\n",
    "Transposition is a very important operation for linear algebra. Although NumPy is capable of correctly doing matrix-vector products correctly **regardless of the orientation of the vector**, it is not the case for products of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.arange(0, 12, 1).reshape((4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we see that the product of a matrix and a vector yields the same result not matter if we transponse the vector (use .T method) or not. Python knows how to multiple a matrix with a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z)\n",
    "print('\\n')\n",
    "print(y)\n",
    "Z @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z)\n",
    "print('\\n')\n",
    "print(y.T)\n",
    "Z @ y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this other example, however, when we transpose the Z matrix, it yields to an error due to the incompatibility of the matrix dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z)\n",
    "print('\\n')\n",
    "print(X)\n",
    "Z @ X  # (4 rows and 3 cols) @ (3 rows and 3 cols) yields (4 rows and 3 cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z.T)\n",
    "print('\\n')\n",
    "print(X)\n",
    "Z.T @ X  # (3 rows and 4 cols) @ (3 rows and 3 cols) yields error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array Methods\n",
    "\n",
    "To not have to go from NumPy arrays to lists back and forth, NumPy contains some functions to know properties of your arrays. Actually, there are more of these functions than in standard Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-4, -2, 1, 3, 5])\n",
    "print(a.max())\n",
    "print(a.min())\n",
    "print(a.sum())\n",
    "print(a.mean())\n",
    "print(a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting functions are `argmax` and `argmin`, which return the index of the maximum and minimum values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.argmax())\n",
    "print(a.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing/Slicing\n",
    "\n",
    "We have already seen briefly that to access individual elements you use the bracket notation: `array[ax_0, ax_1, ...]`, where the `ax_i` denotes the coordinate in the `i`-th axis. You can even use this to assign new values to your elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array([4, 5, 6, 7])\n",
    "print(r[2])\n",
    "r[0] = 198 # Reassigning the value stored in index 0\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a range of rows or columns you can use a colon `:`. A second `:` can be used to indicate the step size. `array[start:stop:stepsize]`. If you leave `start` (`stop`) blank, the selection will go from the very beginning (until the very end) of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(13)**2\n",
    "print(s)\n",
    "\n",
    "# Starting by index 2, until index 10, pick each element. Remember that the last index of the range is not considered\n",
    "print(s[2:10])\n",
    "\n",
    "# Starting by index 2, until index 10, pick every 3 elements \n",
    "print(s[2:10:3])\n",
    "\n",
    "# Starting by index -5, until the end, pick every 2 elements\n",
    "print(s[-5::2])\n",
    "\n",
    "# Starting by index -5, until the end, pick every 2 elements backwards\n",
    "print(s[-5::-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies to matrices or higher-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(36).reshape((6, 6))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick rows 2 to 5, and cols 1 to 3 (remember, row 5 and col 3 not included)\n",
    "r[2:5, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select specific rows and columns, separated by commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick rows 1, 3 and 4, and cols 1 to 3 (remember, col 3 not included)\n",
    "r[[1, 3, 4], 1:3] # Instaed of a range, we use a list of indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful tool is *conditional indexing*, where we apply a function, assignment... only to those elements of an array that satisfy some condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r > 30] = 30\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that there are libraries that make use of random generators (e. randint). NumPy also presents random generators that we can apply to create random arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z = np.random.uniform(0,1,100)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise:** Let's look for the number within a random array that is closest to 0.7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copying Data\n",
    "\n",
    "**Be very careful with copying and modifying arrays in NumPy!** You will see the reason right now. Let's begin defining `r2` as a slice of r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r[:3,:3]\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's set all its elements to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2[:] = 0\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at `r`, we see that it has also been changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proper way of handling selections without modifying the original arrays is through the `copy` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_copy = r.copy()\n",
    "r_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can safely modify `r_copy` without affecting `r`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_copy[:] = 10\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Over Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can iterate over arrays in the same way as you iterate over lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(0, 10, (4,3)) # Here we use the function random.randint from numpy args: (lowest, highest, size)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can iterate by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by row and index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(test):\n",
    "    print(\"Row \"+ str(i) + \" is \" + str(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as with lists, you can use `zip` to iterate over multiple iterables (an iterable is an object that is susceptible of being iterated, which means that we are able to go through all their elements). We can normally iterate over a matrix, but `zip` allows us to use different iterable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test**2\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, j in zip(test, test2):\n",
    "    print(str(i) + \" + \" + str(j) + \" = \" + str(i+j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise**: Create a function that iterates over the columns of a 2-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Saving Data\n",
    "\n",
    "To load and save data NumPy has the `loadtxt` and `savetxt` commands. However, they only work for two-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('numpytest.txt', test) # savetxt function takes as input the file path (arg1) and the array (arg2) \n",
    "np.loadtxt('numpytest.txt') # We load the array from the same file we created before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "When dealing with numeric matrices and vectors in Python, NumPy makes life a lot easier. For more complex data, however, it leaves a bit to be desired. For those used to working with dedicated languages like R, doing data analysis directly with numpy feels like a step back. Fortunately, some nice folks have written the Python Data Analysis Library (a.k.a. [Pandas](http://pandas.pydata.org/)). Pandas provides an R-like DataFrame, produces high quality plots with matplotlib, and integrates nicely with other libraries that expect NumPy arrays.\n",
    "\n",
    "Pandas works with `Series` of data, that then are arranged in `DataFrame`s. A dataframe will be the object closest to an Excel spreadsheet that you will see throughout the course (but of course, given that it is integrated in Python and can be combined with so many different packages, dataframes are much more powerful than Excel spreadsheets). The data in the series can be either qualitative or quantitative data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print('Pandas:', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the series is indexed by default by integers. You can change this indexing by using a dictionary instead of a list for creating the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, `DataFrame`s can be built from two-dimensional arrays, with the ability of labelling columns and indexing the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling a 1000 rows 6 cols 2D array from the standard normal distribution and creating DataFrame\n",
    "u = pd.DataFrame(np.random.randn(1000, 6),\n",
    "                 index=np.arange(0, 3000, 3),\n",
    "                 columns=['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we can take the previous Series and convert them into a dataframe\n",
    "pd.DataFrame(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, it is a bit ugly to deal with large dataframes. There are however some functions that allows to have an idea of the data in a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *describe* function provides basic summary statistic per-column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also change the maximal number of rows that is displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 15)\n",
    "\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing/Slicing in Pandas\n",
    "\n",
    "The easiest way of accessing information in a Pandas dataframe, equivalent to the way used in NumPy, is using the `iloc` command, which relys on the **number indexes** of rows and columns. With this you can also set specific values, do conditional indexing... all that we have seen before in section 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice-in rows index 125 to 132 (132 included!) from columns index 0, 2 and 5\n",
    "u.iloc[125:132, [0, 2, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose specific rows according to their **index names** with the `loc` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice-in rows 375 to 393 (393 included!) from columns A, C and F\n",
    "u.loc[375:393, ['A', 'C', 'F']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual `[]` will select specific rows according to the row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice-in rows index 125 to 132 (132 included!) from columns A, C and F\n",
    "u[125:132][['A', 'C', 'F']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are a few different ways of accessing the data in a Pandas dataframe, that typically have a more \"direct\" connection with the actual content fo the dataframe. Individual or sets of columns can also be accessed by their column names. Choosing one single column will give a Series, while two or more will produce a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u['A'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[['A', 'D']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only that, you can access a single column without the need of brackets []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can access just the elements that satisfy some condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[u.D > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[~(u.D > 2)]  # For the inverse of u.D > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently `query` has been added to `DataFrame` for the same purpose. While it is less powerful than logical indexing, it is often faster and shorter (when names are longer than just `u`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.query('D > 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping `DataFrame`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a Pandas dataframe from scratch by adding new columns each time. This is useful when we have a function that iterates through a series of data and we have to append columns each time we go through the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame() # First we create an empty dataframe\n",
    "\n",
    "df1['sample'] = ['A', 'A', 'A', 'B', 'B', 'B']\n",
    "df1['replicate'] = ['01', '02', '03', '01', '02', '03']\n",
    "df1['protein'] = 'P02768' # If we provide a single value in a column of a dataframe of higher dimensions, this is repeted.\n",
    "df1['value1'] = np.random.randn(6)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting function of Pandas is *pivot*, which allows us to create a derived dataframe that uses values of the columns from the original dataframe as indexes (rows) and columns of the new dataframe, and finally fill it with the values of another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df1 = df1.pivot(index='replicate', columns='sample', values='value1')\n",
    "\n",
    "pivot_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing With `DataFrames`\n",
    "\n",
    "You can calculate with `DataFrames` or their columns (which are `Series`) the same way you could with `arrays`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['value2'] = 1 / df1['value1'] # In this way we replace the column \"value2\" with modified values.\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df1) # We obtain the values of a certain function applied on a dataframe by their columns (Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply functions to the whole dataset or specific columns with the `apply` command. `apply` acts on the whole column at a time (i.e. a Pandas `Series`), so you can compute things that depend on several values of the column, for instance the mean value. To apply functions in a real element-by-element basis the function `applymap` or `Series.apply` should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mn(col):\n",
    "    return sum(col) / len(col)\n",
    "\n",
    "df1[['value1']].apply(mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we try to apply a mathematical operation (mn function) to the whole dataframe?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.apply(mn) # We are trying to get the mean value of string-based columns!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most can be directly calculated (including the given example of the mean), `apply` also works on columns with strings or categorical data, where no mathematical operations are defined. The limit is the imagination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining `DataFrames`\n",
    "\n",
    "Something we will do quite often as scientists is combining data from different sources into one single source. This can be achieved by different commands in Pandas, depending on the actual goal we want.\n",
    "\n",
    "To begin with, appending new rows of data is achieved by the command `append`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "\n",
    "df2['sample'] = ['A', 'A', 'A', 'B', 'B', 'B']\n",
    "df2['replicate'] = ['01', '02', '03', '01', '02', '03']\n",
    "df2['protein'] = 'P69892'\n",
    "df2['value1'] = np.random.randn(6)\n",
    "df2['value2'] = 1 / df2['value1']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result can be obtained with `concat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we need to perform calculations on specific groups of values of the dataframe. These groups may be made by the values contained within a certain column. In the example below we are interested in computing the sum of the values associated to the protains we have stored in the \"protein\" column. This task can be achieved with the function `groupby()`. The function we want to apply is indicated by the function `agg()`, associated to `groupby()` in order to provide the task that we want to perform on the grouped values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('protein').agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('protein').agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample']).agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample', 'replicate']).agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may want to keep the dimensions of the original dataframe while we are performing these calculations. To this purpose we use the function `transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sample').transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('protein')['value1', 'value2'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous function `pivot()` we can generate a derived dataframe by using as index the values contained in certain columns. `pivot_table()` provides also this functionality but also allows us to apply a function to the values within the table as `agg()` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='protein',\n",
    "               columns='sample', \n",
    "               aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='protein',\n",
    "               columns='sample',\n",
    "               aggfunc={'value1': min,\n",
    "                        'value2': max})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving dataframes\n",
    "\n",
    "To load and save Pandas dataframes we will use the `to_csv()` and `read_csv()` commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')\n",
    "pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, as an addition, Pandas has special commands to load and save Excel spreadsheets (yay!). However, to use it you'll need the `openpyxl` and `xlrd` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('test.xlsx', sheet_name='My sheet')\n",
    "pd.read_excel('test.xlsx', 'My sheet', index_col=0)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "comment_magics": true,
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6rc1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "299px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 331.518518,
   "position": {
    "height": "353px",
    "left": "595.965px",
    "right": "20px",
    "top": "2.91667px",
    "width": "629px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
